{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['James', 'France', 44.0, 72000.0, 'No'],\n",
       "       ['Tim', 'Spain', 27.0, 48000.0, 'Yes'],\n",
       "       ['Sarah', 'Germany', 30.0, 54000.0, 'No'],\n",
       "       ['Robert', 'Spain', 38.0, 61000.0, 'No'],\n",
       "       ['Emma', 'Germany', 40.0, nan, 'Yes'],\n",
       "       ['Jennifer', 'France', 35.0, 58000.0, 'Yes'],\n",
       "       ['Linda', 'Spain', nan, 52000.0, 'No'],\n",
       "       ['Thomas', 'France', 48.0, 79000.0, 'Yes'],\n",
       "       ['Ben', 'Germany', 50.0, 83000.0, 'No'],\n",
       "       ['Scarlett', 'France', 37.0, 67000.0, 'Yes']], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/sample.csv').values\n",
    "# dataFrame values: column, index 정보를 가져온다\n",
    "print(type(dataset))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "# X = 전체 행, 국적(1)/나이(2)/연봉(3)\n",
    "X = dataset[:,1:-1]\n",
    "\n",
    "# y = 전체 행, 마지막 열\n",
    "# [범위, idx] -> 1D array\n",
    "# [범위, 범위] -> 2D array\n",
    "y = dataset[:,-1]\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### str to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#LabelEncoder: 문자를 0부터 n까지의 정수로 변환\n",
    "le = LabelEncoder()\n",
    "# X의 첫번째열에 LabelEncoder 적용\n",
    "le.fit(X[:,0])\n",
    "# fit은 실제 변형되지 않고, 정보만 수집\n",
    "# ex) 몇 종류의 문자열이 존재하는지. 변환할 때, 어떠한 문자를 어떠한 숫자로 변환할지 결정\n",
    "X_c = le.transform(X[:,0])\n",
    "# transform은 fit에서 결정된 정보를 기반으로 실제 변환 수행 후 결과 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 44.0, 72000.0],\n",
       "       [2, 27.0, 48000.0],\n",
       "       [1, 30.0, 54000.0],\n",
       "       [2, 38.0, 61000.0],\n",
       "       [1, 40.0, nan],\n",
       "       [0, 35.0, 58000.0],\n",
       "       [2, nan, 52000.0],\n",
       "       [0, 48.0, 79000.0],\n",
       "       [1, 50.0, 83000.0],\n",
       "       [0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X에서 첫번째 column 삭제 X_c 결합\n",
    "X_tmp = np.delete(X, 0, axis=1)\n",
    "# X_tmp에 X_c 결합\n",
    "# concatenate으로 두 개의 ndarray를 결합할 때는 반드시 둘의 ndim이 동일해야 함\n",
    "# X_c를 2D array로 변경\n",
    "# X_tmp.shape = (10, 3)\n",
    "# X_c를 X_tmp에 좌우 결합하기 위해 X_c.shape = (10, 1)로 reshape\n",
    "# 1D array인 array를 (n, 1)로 변경할 경위 arr.reshape(-1, 1)\n",
    "np.concatenate((X_c.reshape(-1, 1), X_tmp), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. One-Hot Encoder\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X[:,:1]) # == X[:,0].reshape(-1,1)\n",
    "# OneHotEncoder의 경우 결과값이 2D array로 나오기 때문에 무조건 2D로 만들어야 함.\n",
    "# OneHotEncoder.fit: 데이터 분석, 전략 수집, 몇 개의 범주가 있는가, 어떠한 번주를 어떠한 열에 대응할 것인가\n",
    "X_ohe_c = ohe.transform(X[:,:1]).toarray()\n",
    "# OneHotEncoder.transform의 결과는 sparse matrix로 ndarray로 변경하기 위해 toarray() 사용\n",
    "# sparse matrix 타입을 이용하는 이유는 메모리 공간을 아끼기 위함.\n",
    "X_ohe_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 nan]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 nan 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "X_tmp = np.delete(X,0,axis=1)\n",
    "# X_ohe_c는 2D array이므로 shape를 변경하지 않아도 됨\n",
    "X_new_ohe = np.concatenate((X_ohe_c, X_tmp), axis=1)\n",
    "print(X_new_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train / test data 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3) (8,)\n",
      "(2, 3) (2,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 37.0 67000.0]\n",
      " ['France' 35.0 58000.0]]\n"
     ]
    }
   ],
   "source": [
    "# train_test_split은 data를 임의로 shuffle한 후, 분리함 (X와 y동일한 순서로 shuffle)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "\n",
    "# model의 성능을 비교하기 위해서는 항상 동일한 train/test dataset을 사용해야 함\n",
    "# 매번 실행할 때마다, train/tst data가 변경되므로, 변경되지 않도록 설정하는 인자 사용(random_state)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train data와 test data에 대한 주의 사항\n",
    "- test data는 training 과정에서 어떠한 관여도 해서는 안된다\n",
    "- ex) One-Hot Encoding 적용: train/test data 분리 -> train data에만 fit을 적용<br>\n",
    "    -> fit의 결과를 test data에 적용하여 변환\n",
    "- ex) scaling 적용: train/test data 분리 -> train data에만 fit 적용<br>\n",
    "    -> fit의 결과를 test data에 적용하여 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2) (10,)\n"
     ]
    }
   ],
   "source": [
    "# scaler: 데이터의 범위를 조정\n",
    "X = dataset[:, 2:-1]\n",
    "y = dataset[:, -1]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling 적용하기 전, train_test_split으로 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.78492777 -0.72132045]\n",
      " [ 0.55157087  0.58171004]\n",
      " [ 1.14557027  1.23322529]\n",
      " [-1.52742702 -1.09361488]\n",
      " [-0.33942823 -0.44209963]\n",
      " [        nan -1.27976209]\n",
      " [-0.48792808  0.11634201]\n",
      " [ 1.44256996  1.60551972]]\n",
      "[[-0.04242853         nan]\n",
      " [-1.97292657 -1.65205652]]\n",
      "(8, 2) (2, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "# 평균은 0, 분산(표준편차)은 1로 변경한 데이터 (주로 -3~3 정도의 값)\n",
    "# fit에는 train 데이터만 적용\n",
    "sc.fit(X_train)\n",
    "# 변환을 위한 전략 수집(데이터의 평균, 분산 등 계산)\n",
    "\n",
    "# X_train 변환\n",
    "X_train_sc = sc.transform(X_train)\n",
    "# 0에 가까울 수록 평균에 가까운 값\n",
    "\n",
    "# X_test 변환 (fit은 적용하지 않고 X_train을 통해 수립한 전략으로 변환만 수행)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "\n",
    "print(X_train_sc)\n",
    "print(X_test_sc)\n",
    "print(X_train_sc.shape, X_test_sc.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
